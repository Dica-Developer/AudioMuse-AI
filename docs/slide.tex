\documentclass{beamer}

% Theme selection
\usetheme{Madrid} % Or any other Beamer theme you prefer

% Title information
\title{AudioMuse-AI: Smart Playlist Generation for Your Jellyfin Homelab}
\author{NeptuneHub}
\date{\today}

\begin{document}

% Title slide
\begin{frame}
    \titlepage
\end{frame}

% What is AudioMuse-AI?
\begin{frame}{What is AudioMuse-AI?}
    AudioMuse-AI is a Dockerized application that intelligently transforms your Jellyfin music library. It uses deep audio analysis and AI to understand your music's characteristics, generating smart, curated playlists. Think of it as an intelligent DJ for your homelab, enhancing your self-hosted music experience.
\end{frame}

% Why is AudioMuse-AI Useful?
\begin{frame}{Why AudioMuse-AI is Useful for Your Homelab?}
    \begin{itemize}
        \item \textbf{Effortless Playlists:} Say goodbye to manual curation; AudioMuse-AI automates playlist creation for you.
        \item \textbf{Rediscover Music:} Uncover hidden gems by grouping tracks based on their unique audio features.
        \item \textbf{Mood-Based Listening:} Generate playlists perfectly suited for any mood or activity, from high-energy workouts to relaxing evenings.
        \item \textbf{Seamless Jellyfin Integration:} Playlists are created directly within your Jellyfin library, ready to play.
        \item \textbf{Open Source \& Customizable:} You have full control, allowing you to fine-tune analysis and clustering parameters to your liking.
    \end{itemize}
\end{frame}

% Quick Start / Deployment
\begin{frame}{Quick Start: Deploying in Your Homelab}
    AudioMuse-AI is designed for easy deployment using Docker Compose (for local setups) or Kubernetes (K3S).

    \begin{itemize}
        \item \textbf{Prerequisites:} Ensure you have Docker and Docker Compose (local) or a K3S cluster with \texttt{kubectl} (Kubernetes).
        \item \textbf{Configuration:} Update provided \texttt{docker-compose.yaml} or \texttt{deployment.yaml} files. Key settings include your Jellyfin URL, API token, user ID, and database/Redis credentials. You can also configure the Gemini API key for AI naming.
        \item \textbf{Deployment:}
        \begin{itemize}
            \item For Docker Compose: \texttt{docker compose up -d --scale audiomuse-ai-worker=2}.
            \item For Kubernetes: \texttt{kubectl apply -f deployment.yaml}.
        \end{itemize}
        \item \textbf{Access:} Once deployed, access the web UI at \texttt{http://<YOUR-IP>:8000}.
    \end{itemize}
\end{frame}

% Workflow Overview
\begin{frame}{How It Works: Workflow Overview}
    AudioMuse-AI transforms your music through a structured workflow:
    \begin{enumerate}
        \item \textbf{User Initiation:} You start analysis or clustering tasks from the web UI.
        \item \textbf{Task Queuing:} Jobs are sent to a background queue (Redis Queue) for asynchronous processing, keeping the UI responsive.
        \item \textbf{Parallel Processing:} Multiple workers handle tasks simultaneously, speeding up analysis for large libraries.
        \item \textbf{Analysis Phase:}
        \begin{itemize}
            \item Audio is downloaded from Jellyfin and analyzed by \textbf{Essentia} and \textbf{TensorFlow}.
            \item Features like tempo, key, energy, moods, and genres are extracted.
            \item Results are saved to a PostgreSQL database.
        \end{itemize}
        \item \textbf{Clustering Phase:}
        \begin{itemize}
            \item An advanced evolutionary algorithm groups analyzed tracks into cohesive playlists.
            \item Optionally, AI models (Ollama or Gemini) generate creative playlist names.
            \item Final playlists are created directly in Jellyfin.
        \end{itemize}
    \end{enumerate}
\end{frame}

% Audio Analysis Algorithm Deep Dive
\begin{frame}{Deep Dive: Audio Analysis Algorithm}
    AudioMuse-AI extracts rich features from your music library:
    \begin{itemize}
        \item \textbf{Audio Loading \& Preprocessing:} Tracks are downloaded from Jellyfin and consistently resampled to 16000 Hz.
        \item \textbf{Core Feature Extraction (Essentia):}
        \begin{itemize}
            \item \textbf{Tempo:} Uses \texttt{RhythmExtractor2013} for BPM.
            \item \textbf{Key \& Scale:} Identifies musical key and scale.
            \item \textbf{Energy:} Calculates normalized average energy for intensity.
        \end{itemize}
        \item \textbf{Embedding Generation (TensorFlow \& Essentia):}
        \begin{itemize}
            \item \textbf{MusiCNN Embeddings:} A 200-dimensional vector captures high-level semantic information using pre-trained TensorFlow models.
        \end{itemize}
        \item \textbf{Prediction Models (TensorFlow \& Essentia):}
        \begin{itemize}
            \item Predicts primary tags/genres (e.g., 'rock', 'pop').
            \item Predicts specific moods and characteristics like 'danceable', 'happy', 'sad'.
        \end{itemize}
        \item \textbf{Feature Vector Preparation:} All extracted features are normalized and standardized into a single numerical vector per track, ready for clustering.
    \end{itemize}
\end{frame}

% Example: Audio Analysis Output
\begin{frame}{Example: Audio Analysis Output}
    \begin{exampleblock}{Analyzed Track: "My Awesome Song by Great Artist"}
    \small
    After analysis, a track yields detailed attributes and a numerical feature vector:
    \begin{itemize}
        \item \textbf{Metadata:}
        \begin{itemize}
            \item \textbf{Tempo:} 120.5 BPM
            \item \textbf{Key:} D Major
            \item \textbf{Energy:} 0.72 (normalized)
        \end{itemize}
        \item \textbf{Moods \& Other Features (Predicted Scores):}
        \begin{itemize}
            \item \textbf{Moods:} \{'happy': 0.88, 'energetic': 0.75, 'party': 0.62, ...\}
            \item \textbf{Other Features:} \{'danceable': 0.91, 'aggressive': 0.15, ...\}
        \end{itemize}
        \item \textbf{Resulting Feature Vector (Simplified):}
        \begin{center}
            $[\underbrace{0.65}_{\text{norm. tempo}}, \underbrace{0.82}_{\text{norm. energy}}, \underbrace{0.88}_{\text{happy}}, \underbrace{0.65}_{\text{rock}}, \underbrace{0.91}_{\text{danceable}}, \underbrace{0.15}_{\text{sad}}, ...]$
        \end{center}
    \end{itemize}
    This comprehensive vector forms the basis for subsequent clustering.
    \end{exampleblock}
\end{frame}

% Combined Deep Dive: Clustering & Evolutionary Approach
\begin{frame}{Deep Dive: Clustering \& Evolutionary Approach}
    AudioMuse-AI intelligently groups songs into playlists using various clustering algorithms, such as K-Means, DBSCAN, and Gaussian Mixture Models (GMM). The key to finding optimal playlist configurations is an advanced \textbf{Monte Carlo evolutionary approach}.

    \begin{itemize}
        \item \textbf{Multiple Iterations:} The system runs clustering hundreds or thousands of times (default 1000), experimenting with different parameters for the chosen algorithms and PCA.
        \item \textbf{Evolutionary Strategy:} It "learns" from good solutions by remembering "elite" parameter sets. These elite sets are then mutated to explore their "neighborhood" and find even better configurations.
        \item \textbf{Comprehensive Scoring:} Each clustering outcome is evaluated with a composite score. This score balances factors like overall playlist diversity, the consistency (purity) within individual playlists, and internal clustering metrics.
        \item The configuration that yields the best overall score is then chosen to generate your final Jellyfin playlists.
    \end{itemize}
\end{frame}

% Example: Clustering Output (without AI Naming)
\begin{frame}{Example: Clustering Output (without AI Naming)}
    \begin{exampleblock}{Playlists Generated by Clustering Algorithm (Default Naming)}
    \small
    After the clustering algorithm groups similar songs, playlists are named based on their predominant characteristics extracted from the cluster centroids:
    \begin{itemize}
        \item \textbf{Playlist 1:} \texttt{Rock\_Fast\_Danceable}
            \begin{itemize}
                \item Songs in this playlist exhibit high scores for Rock genre, Fast tempo, and Danceable attributes.
            \end{itemize}
        \item \textbf{Playlist 2:} \texttt{Chillout\_Medium\_Relaxed}
            \begin{itemize}
                \item This playlist contains songs characterized by Chillout moods, Medium tempo, and a Relaxed vibe.
            \end{itemize}
        \item \textbf{Playlist 3:} \texttt{Pop\_Upbeat\_Happy}
            \begin{itemize}
                \item A collection of songs identified with Pop characteristics, an Upbeat tempo, and a Happy mood.
            \end{itemize}
    \end{itemize}
    These names are descriptive but can sometimes lack a creative touch.
    \end{exampleblock}
\end{frame}

% AI Playlist Naming
\begin{frame}{AI Playlist Naming: Adding Creativity}
    Add a creative touch to your generated playlists!
    \begin{itemize}
        \item After clustering, AudioMuse-AI can use an AI model (Ollama or Google Gemini) to generate descriptive, human-readable names.
        \item \textbf{Input to AI:} Key characteristics from the cluster's centroid (moods, tempo, etc.) and sample songs are provided.
        \item \textbf{Prompt Engineering:} Carefully crafted prompts guide the AI to generate concise names reflecting the playlist's vibe.
    \end{itemize}
\end{frame}

% Example: AI Playlist Naming
\begin{frame}{Example: AI Playlist Naming}
    \begin{exampleblock}{AI-Generated Playlist Names}
    \small
    Consider a cluster identified with high "Rock" mood, "Fast" tempo, and "Danceable" characteristics.
    \begin{itemize}
        \item \textbf{Without AI (Default Name):}
        \begin{center} \texttt{Rock\_Fast\_Danceable} \end{center}
        This name is functional but purely descriptive.
        \item \textbf{With AI (Evocative Name):} The AI processes the cluster's attributes and suggests a more engaging name. For the same cluster, it might propose:
        \begin{center} \textit{Rock N' Roll Rumble} \end{center}
        This name instantly conveys energy and style. Other possibilities could include: \textit{High-Energy Rock Mix}, \textit{Amped Up Anthems}, or \textit{Dancefloor Rockers}.
    \end{itemize}
    This feature transforms generic labels into appealing and memorable playlist titles, enhancing discoverability.
    \end{exampleblock}
\end{frame}

% Key Technologies
\begin{frame}{Key Technologies Under the Hood}
    Built with a robust stack of open-source technologies:
    \begin{itemize}
        \item \textbf{Flask:} Lightweight web interface and API.
        \item \textbf{Redis Queue (RQ):} Background job processing for analysis and clustering.
        \item \textbf{Essentia-TensorFlow:} Core audio analysis, feature extraction, and deep learning models.
        \item \textbf{scikit-learn:} Machine learning algorithms for clustering and dimensionality reduction.
        \item \textbf{PostgreSQL:} Persistent storage for analyzed track data and playlist structures.
        \item \textbf{Ollama / Google Gemini API:} Optional AI models for intelligent playlist naming.
        \item \textbf{Jellyfin API:} Direct integration to manage your media and playlists.
        \item \textbf{Docker / OCI Containers:} Ensures easy and consistent deployment in your homelab.
    \end{itemize}
\end{frame}

% Future Possibilities
\begin{frame}{Future Possibilities}
    This is just the beginning!
    \begin{itemize}
        \item \textbf{Integration into Music Clients:} Directly use for playlist creation or instant mixes within your favorite players.
        \item \textbf{Jellyfin Plugin:} Seamless integration directly within the Jellyfin UI for a single, easy-to-use front-end.
        \item \textbf{Cross-Platform Sync:} Export playlists to .m3u or sync to external platforms.
    \end{itemize}
\end{frame}

% Thank You slide
\begin{frame}
    \centering
    \textbf{Thank You!}

    \vspace{1cm}

    \textbf{AudioMuse-AI: Bring Smart Playlists to Your Jellyfin Homelab}

    \vspace{0.5cm}

    \url{https://github.com/NeptuneHub/AudioMuse-AI}
\end{frame}

\end{document}
